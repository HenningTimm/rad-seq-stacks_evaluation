workflows = ["no_dedup", "with_dedup"]

configfile: "config.yaml"

rule all:
    input:
        "01_compared_stack_sizes.pdf",
        "01_compared_stack_counts.pdf",
        "01_cstacks_locus_number_accumulation.pdf",
        "01_ustacks_nr_blacklisted_and_mean_coverage.pdf"


rule run_subworkflow:
    input:
        individuals="rad-seq-stacks_{workflow}/individuals.tsv",
        units="rad-seq-stacks_{workflow}/units.tsv",
    output:
        "rad-seq-stacks_{workflow}/plots/distribution_comparison/stacks_counts.pdf",
        "rad-seq-stacks_{workflow}/plots/distribution_comparison/stacks_size_distribution.pdf",
        "rad-seq-stacks_{workflow}/plots/distribution_comparison/sizes_dataframe.csv",
        "rad-seq-stacks_{workflow}/plots/distribution_comparison/counts_dataframe.csv",
    params:
        cores=config["cores_per_subworkflow"]
    shell:
        "cd rad-seq-stacks_{wildcards.workflow} && "
        "snakemake --use-conda --jobs {params.cores} -F"


rule plot_comparison:
    input:
        sizes_no_dedup="rad-seq-stacks_no_dedup/plots/distribution_comparison/sizes_dataframe.csv",
        sizes_with_dedup="rad-seq-stacks_with_dedup/plots/distribution_comparison/sizes_dataframe.csv",
        counts_no_dedup="rad-seq-stacks_no_dedup/plots/distribution_comparison/counts_dataframe.csv",
        counts_with_dedup="rad-seq-stacks_with_dedup/plots/distribution_comparison/counts_dataframe.csv",
    output:
        violin_path="01_compared_stack_sizes.pdf",
        scatter_path="01_compared_stack_counts.pdf",
    params:
        threshold=config["plotting_threshold"]
    conda:
        "rad-seq-stacks_with_dedup/envs/plot_stacks_dist.yaml"
    script:
        "scripts/compare_pipelines.py"


rule plot_deduplication_influence:
    input:
        individuals_with="rad-seq-stacks_with_dedup/individuals.tsv",
        individuals_no="rad-seq-stacks_no_dedup/individuals.tsv",
        config_with="rad-seq-stacks_with_dedup/config.yaml",
        config_no="rad-seq-stacks_no_dedup/config.yaml",
        # Sentinel file to assure the subworkflow has been run. Not actually used.
        _sentinel=expand("rad-seq-stacks_{workflow}/plots/distribution_comparison/counts_dataframe.csv", workflow=workflows),
    output:
        accumulation="01_cstacks_locus_number_accumulation.pdf",
        blacklisted="01_ustacks_nr_blacklisted_and_mean_coverage.pdf",
        endpoints="01_endpoints.pdf",
    conda:
        "rad-seq-stacks_with_dedup/envs/plot_stacks_dist.yaml"
    script:
        "scripts/parse_logs.py"


rule rage_dataset:
    output:
        "testdata/testdata_1.fastq.gz",
        "testdata/testdata_2.fastq.gz",
        "testdata/testdata_gt.yaml",
        "testdata/testdata_barcodes.txt",
    conda:
        "rad-seq-stacks_with_dedup/envs/testdata.yaml"
    params:
        loci=config["ddrage"]["loci"],
        individuals=config["ddrage"]["individuals"],
        output_prefix=config["ddrage"]["output_prefix"],
        ds_name=config["ddrage"]["ds_name"],
        hrl_number=config["ddrage"]["hrl_number"],
        prob_ID=config["ddrage"]["prob_ID"],
        prob_het=config["ddrage"]["prob_het"],
        event_probs=config["ddrage"]["event_probs"],
        prob_seq_error=config["ddrage"]["prob_seq_error"],
    shell:
        "ddrage --name {params.ds_name} -l {params.loci} -n {params.individuals} -o {params.output_prefix} "
        "--hrl-number {params.hrl_number} --prob-incomplete-digestion {params.prob_ID} "
        "--prob-heterozygous {params.prob_het} --event-probabilities {params.event_probs} "
        "-z --prob-seq-error {params.prob_seq_error} && "
        "mv {params.output_prefix}/logs/* {params.output_prefix}/ && "
        "rename -f 's/[ACGT]{{6}}_//' {params.output_prefix}/* && "
        "mv {params.output_prefix}/* testdata/ && "
        "rm -r {params.output_prefix}"


rule remove_annotation:
    input:
        fq1="testdata/testdata_1.fastq.gz",
        fq2="testdata/testdata_2.fastq.gz",
    output:
        fq1="testdata/testdata_1_noheader.fastq.gz",
        fq2="testdata/testdata_2_noheader.fastq.gz",
        gt1="testdata/testdata_1_annotation.txt",
        gt2="testdata/testdata_2_annotation.txt",
    conda:
        "rad-seq-stacks_with_dedup/envs/testdata.yaml"
    shell:
        "remove_annotation {input.fq1} {input.fq2}"


rule units_and_individuals:
    input:
        fq1="testdata/testdata_1_noheader.fastq.gz",
        fq2="testdata/testdata_2_noheader.fastq.gz",
        bc_file="testdata/testdata_barcodes.txt",
    output:
        individuals="rad-seq-stacks_{pipeline_config}/individuals.tsv",
        units="rad-seq-stacks_{pipeline_config}/units.tsv",
    script:
        "scripts/generate_sample_files.py"
