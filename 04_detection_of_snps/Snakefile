configfile: "config.yaml"

rule all:
    input:
        "04_snps_compared_stack_sizes.pdf",
        "04_snps_compared_stack_counts.pdf",
        "04_snps_FP_snps.pdf",
        "04_snps_TP_snps.pdf",
        "04_snps_sensitivity.pdf",
        "04_snps_split_loci.pdf",

rule run_subworkflow:
    input:
        "rad-seq-stacks_{workflow}/individuals.tsv",
        "rad-seq-stacks_{workflow}/units.tsv",
    output:
        "rad-seq-stacks_{workflow}/plots/distribution_comparison/stacks_counts.pdf",
        "rad-seq-stacks_{workflow}/plots/distribution_comparison/stacks_size_distribution.pdf",
        "rad-seq-stacks_{workflow}/plots/distribution_comparison/sizes_dataframe.csv",
        "rad-seq-stacks_{workflow}/plots/distribution_comparison/counts_dataframe.csv",
        expand(
            "rad-seq-stacks_{{workflow}}/stacks/{parameters}/catalog.fa.gz",
            workflow=config["workflows"],
            parameters=[f"n={n}.M={M}.m={m}" for n, M, m in config["parameter_sets"]],
        ),
        expand(
            "rad-seq-stacks_{{workflow}}/calls/{parameters}/populations.snps.vcf",
            workflow=config["workflows"],
            parameters=[f"n={n}.M={M}.m={m}" for n, M, m in config["parameter_sets"]],
        ),
    params:
        cores=config["cores_per_subworkflow"]
    shell:
        "cd rad-seq-stacks_{wildcards.workflow} && "
        "snakemake --use-conda --jobs {params.cores} -F"

rule plot_comparison:
    input:
        sizes_no_dedup="rad-seq-stacks_no_dedup/plots/distribution_comparison/sizes_dataframe.csv",
        sizes_with_dedup="rad-seq-stacks_with_dedup/plots/distribution_comparison/sizes_dataframe.csv",
        counts_no_dedup="rad-seq-stacks_no_dedup/plots/distribution_comparison/counts_dataframe.csv",
        counts_with_dedup="rad-seq-stacks_with_dedup/plots/distribution_comparison/counts_dataframe.csv",
    output:
        violin_path="04_snps_compared_stack_sizes.pdf",
        scatter_path="04_snps_compared_stack_counts.pdf",
    params:
        threshold=config["plotting_threshold"]
    conda:
        "rad-seq-stacks_with_dedup/envs/plot_stacks_dist.yaml"
    script:
        "scripts/compare_pipelines.py"

rule rage_dataset:
    output:
        "testdata/testdata_1.fastq.gz",
        "testdata/testdata_2.fastq.gz",
        "testdata/testdata_gt.yaml",
        "testdata/testdata_barcodes.txt",
    conda:
        "rad-seq-stacks_with_dedup/envs/testdata.yaml"
    params:
        loci=config["ddrage"]["loci"],
        individuals=config["ddrage"]["individuals"],
        output_prefix=config["ddrage"]["output_prefix"],
        ds_name=config["ddrage"]["ds_name"],
        hrl_number=config["ddrage"]["hrl_number"],
        prob_ID=config["ddrage"]["prob_ID"],
        prob_het=config["ddrage"]["prob_het"],
        event_probs=config["ddrage"]["event_probs"],
        prob_seq_error=config["ddrage"]["prob_seq_error"],
        mutation_probs=config["ddrage"]["mutation_probs"],
        read_length=config["ddrage"]["read_length"],
    shell:
        "ddrage --name {params.ds_name} -l {params.loci} -n {params.individuals} -o {params.output_prefix} "
        "--hrl-number {params.hrl_number} --prob-incomplete-digestion {params.prob_ID} --read-length {params.read_length} "
        "--prob-heterozygous {params.prob_het} --event-probabilities {params.event_probs} "
        "-z --prob-seq-error {params.prob_seq_error} --mutation-type-probabilities {params.mutation_probs} && "
        "mv {params.output_prefix}/logs/* {params.output_prefix}/ && "
        "rename -f 's/[ACGT]{{6}}_//' {params.output_prefix}/* && "
        "mv {params.output_prefix}/* testdata/ && "
        "rm -r {params.output_prefix}"


rule remove_annotation:
    input:
        fq1="testdata/testdata_1.fastq.gz",
        fq2="testdata/testdata_2.fastq.gz",
    output:
        fq1="testdata/testdata_1_noheader.fastq.gz",
        fq2="testdata/testdata_2_noheader.fastq.gz",
        gt1="testdata/testdata_1_annotation.txt",
        gt2="testdata/testdata_2_annotation.txt",
    conda:
        "rad-seq-stacks_with_dedup/envs/testdata.yaml"
    shell:
        "remove_annotation {input.fq1} {input.fq2}"


rule units_and_individuals:
    input:
        fq1="testdata/testdata_1_noheader.fastq.gz",
        fq2="testdata/testdata_2_noheader.fastq.gz",
        bc_file="testdata/testdata_barcodes.txt",
    output:
        individuals="rad-seq-stacks_{pipeline_config}/individuals.tsv",
        units="rad-seq-stacks_{pipeline_config}/units.tsv",
    script:
        "scripts/generate_sample_files.py"



rule index_stacks_loci:
    input:
        "rad-seq-stacks_{pipeline_config}/stacks/n={max_locus_mm}.M={max_individual_mm}.m={min_reads}/catalog.fa.gz",
    output:
        fa="rad-seq-stacks_{pipeline_config}/stacks/n={max_locus_mm}.M={max_individual_mm}.m={min_reads}/catalog.fa",
        fai="rad-seq-stacks_{pipeline_config}/stacks/n={max_locus_mm}.M={max_individual_mm}.m={min_reads}/catalog.fa.fai"
    conda:
        "rad-seq-stacks_with_dedup/envs/samtools.yaml"
    shell:
        """
        gunzip -k {input}
        samtools faidx {output.fa}
        """


rule compare_loci:
    input:
        fa="rad-seq-stacks_{pipeline_config}/stacks/n={max_locus_mm}.M={max_individual_mm}.m={min_reads}/catalog.fa",
        fai="rad-seq-stacks_{pipeline_config}/stacks/n={max_locus_mm}.M={max_individual_mm}.m={min_reads}/catalog.fa.fai",
        vcf="rad-seq-stacks_{pipeline_config}/calls/n={max_locus_mm}.M={max_individual_mm}.m={min_reads}/populations.snps.vcf",
        gt="testdata/testdata_gt.yaml",
    output:
        "validation/{pipeline_config}/n={max_locus_mm}.M={max_individual_mm}.m={min_reads}.validation.yaml"
    conda:
        "rad-seq-stacks_with_dedup/envs/testdata.yaml"
    params:
        read_length=config["ddrage"]["read_length"],
    shell:
        "python scripts/evaluate_stacks_results.py --read-length {params.read_length} "
        "--ground-truth {input.gt} --stacks-snps-file {input.vcf} --stacks-fasta-file {input.fa} -o {output}"


rule aggregate_snp_detection_results:
    input:
        validation_files=expand(
            "validation/{workflow}/{parameters}.validation.yaml",
            workflow=config["workflows"],
            parameters=[f"n={n}.M={M}.m={m}" for n, M, m in config["parameter_sets"]],
        ),
    output:
        stats_file="results/aggregated_snp_statistics.txt"
    conda:
        "rad-seq-stacks_with_dedup/envs/testdata.yaml"
    script:
        "scripts/parse_validation_files.py"

rule plot_snp_results:
    input:
        stats_file="results/aggregated_snp_statistics.txt"
    output:
        fp_snps="04_snps_FP_snps.pdf",
        tp_snps="04_snps_TP_snps.pdf",
        sensitivity="04_snps_sensitivity.pdf",
        split_loci="04_snps_split_loci.pdf",
    conda:
        "rad-seq-stacks_with_dedup/envs/testdata.yaml"
    script:
        "scripts/snp_evaluation.py"

