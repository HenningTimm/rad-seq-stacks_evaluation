configfile: "config.yaml"

rule all:
    input:
        expand(
            "05_pipeline_{workflow}/plots/distribution_comparison/stacks_counts.pdf",
            workflow=config["workflows"],
        ),
        expand(
            "05_pipeline_{workflow}/plots/distribution_comparison/stacks_size_distribution.pdf",
            workflow=config["workflows"],
        ),
        expand("05_compared_stack_sizes_threshold={t}.pdf",
               t=config["plotting_thresholds"],
        ),

rule run_subworkflow:
    input:
        "pipeline_{workflow}/individuals.tsv",
        "pipeline_{workflow}/units.tsv",
    output:
        "pipeline_{workflow}/plots/distribution_comparison/stacks_counts.pdf",
        "pipeline_{workflow}/plots/distribution_comparison/stacks_size_distribution.pdf",
        "pipeline_{workflow}/plots/distribution_comparison/sizes_dataframe.csv",
        "pipeline_{workflow}/plots/distribution_comparison/counts_dataframe.csv",
    params:
        cores=config["cores_per_subworkflow"]
    shell:
        "cd pipeline_{wildcards.workflow} && "
        "snakemake --use-conda --jobs {params.cores} -F"

rule plot_comparison:
    input:
        sizes_no_dedup="pipeline_no_dedup/plots/distribution_comparison/sizes_dataframe.csv",
        sizes_with_dedup="pipeline_with_dedup/plots/distribution_comparison/sizes_dataframe.csv",
        counts_no_dedup="pipeline_no_dedup/plots/distribution_comparison/counts_dataframe.csv",
        counts_with_dedup="pipeline_with_dedup/plots/distribution_comparison/counts_dataframe.csv",
    output:
        violin_path="05_compared_stack_sizes_threshold={threshold}.pdf",
        point_path="05_compared_stack_counts_threshold={threshold}.pdf",
        scatter_path="05_scatterplot_stack_counts_threshold={threshold}.pdf",
    conda:
        "pipeline_with_dedup/envs/plot_stacks_dist.yaml"
    script:
        "scripts/compare_pipelines.py"
